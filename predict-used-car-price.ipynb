{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67167,"databundleVersionId":7461897,"sourceType":"competition"},{"sourceId":6478229,"sourceType":"datasetVersion","datasetId":3742543},{"sourceId":8755612,"sourceType":"datasetVersion","datasetId":5259789},{"sourceId":8755630,"sourceType":"datasetVersion","datasetId":5259802}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport  matplotlib.pyplot  as plt\n\nimport warnings\n\n%matplotlib inline \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n#\npd.options.mode.use_inf_as_na = True\nwarnings.filterwarnings('ignore')\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font size='+3' color=blue> <b>Problem Statement </b></font> \n\nThis project with \n- 4009 sample point with 11 feature 1 `price` target column, 3 numerical features\n\n- There are soming missing values in `fuel_type,accident clean_title`. \n- The values in `price milage` need to be formated into numerical values\n- for object-type features e.g. `[brand model engine transmission, ext_col, int_col]` ","metadata":{}},{"cell_type":"markdown","source":"# Load/Check Dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-13T23:39:11.886712Z","iopub.execute_input":"2024-06-13T23:39:11.887168Z","iopub.status.idle":"2024-06-13T23:39:11.892349Z","shell.execute_reply.started":"2024-06-13T23:39:11.887128Z","shell.execute_reply":"2024-06-13T23:39:11.891053Z"}}},{"cell_type":"code","source":"df_test=pd.read_csv('/kaggle/input/kagglextest/test.csv')\nprint('The Full dataset is {}. with {} samples and {} columns'.format(df_test.shape,df_test.shape[0],df_test.shape[1]))\nprint('===')\nprint(df_test.info())\nid_test=df_test['id']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=pd.read_csv('/kaggle/input/kagglex-train/train.csv')\nprint('The Full dataset is {}. with {} samples and {} columns'.format(df_train.shape,df_train.shape[0],df_train.shape[1]))\nprint('===')\nprint(df_train.info())\nprint('===')\nprint(df_train.describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train=df_train['price']\ndf_train.drop(['price'],axis=1,inplace=True)\n\ndf=pd.concat([df_train,df_test],ignore_index=True,axis=0)\nprint(f\"The train set is from 0 to {df_train.shape[0]-1}\\n\\\nthe test set is from {df_train.shape[0]} to end\")\nprint(f\" The df shape is {df.shape}\")\ndf.drop(['id'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_org=pd.read_csv('/kaggle/input/used-car-price-prediction-dataset/used_cars.csv')\nprint('The Full dataset is {}. with {} samples and {} columns'.format(df_org.shape,df_org.shape[0],df_org.shape[1]))\nprint('===')\nprint(df_org.info)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check duplication\ndf.duplicated().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check missing values\ndef check_miss_value(df):\n    '''\n    check the missing value in the dataset\n    args:\n        df pd dataframe\n    return a barh plot or \n    '''\n    miss=df.isnull().sum()\n    miss=miss[miss>0]\n    miss.sort_values(inplace=True)\n    \n    try:\n        print(miss)\n        miss.plot.barh()\n    except:\n        print(\"No value missing\")\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check missing values\ncheck_miss_value(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the number of unique values for each feature\ndf.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop clean_title\ndf.drop(['clean_title'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check numerical variables\ndf.select_dtypes(include=[np.number]).describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check categorical variables\ndf.select_dtypes(exclude=[np.number]).describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check it there are some patten in the value\n# of each categrical value\nfor col in df.select_dtypes('O').columns:\n    print()\n    print(col)\n    print(df[col].nunique())\n    if df[col].nunique() <50:\n        print(df[col].unique())\n    else:\n        print(df[col].unique()[:50])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_cols=['fuel_type','accident']\nfor i in np.arange( len(features_cols)):\n    print(df[features_cols[i]].value_counts())\n    fig =plt.figure()\n    df[features_cols[i]].value_counts().plot.barh()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>[comments]</b>\n\n- Observiously the dtype of milage should be int and the dtype of price should be float\n\n- for object-type features e.g. `[brand model engine transmission, ext_col, int_col]` have a wide range of values, it is better to only focus on the top 5 and group others \n- for numberical features,`milage_format, milage`  are continuous while `model_year` is discrete","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing\n \n- drop unimportant features `['model','ext_col','int_col','clean_title']`\n4. reduce/format cardinality for categorical variables i.e. `['fueltype','transmission','engine','accident']`","metadata":{}},{"cell_type":"code","source":"# format dtypes for org_dataset\n# df['price']=df['price'].str.replace('$', '').str.replace(',', '').astype(float)\n# df['milage']=df['milage'].str.replace(',','').str.replace(' mi.', '').astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# accident\ndf['accident']=df['accident'].apply(lambda x:0 if 'None' in str(x) else 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean/formate\ndf['fuel_type']=df['fuel_type'].apply(lambda x:\n                                      np.nan if str(x).strip()=='–' else \n                                      'electric' if str(x).strip()=='not supported' else x)\n\nfeatures_cols=['fuel_type']\nfor i in np.arange( len(features_cols)):\n    print(i)\n    fig =plt.figure()\n    df[features_cols[i]].value_counts(normalize=True).plot.barh()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trannsmission\ndf['transmission'].value_counts().head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trannsmission: A/T or not \ndf['transmission']=df['transmission'].str.contains('A/T|Automatic',case=False).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# process engine\ndf['engine'].value_counts().head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# process engine\nhp=df['engine'].apply(lambda x:x.split('HP')[0]).apply(pd.to_numeric,errors='coerce')\nliters=df['engine'].apply(lambda x:x.split('L')[0].split('Liter')[0].split(' ')[-1]).apply(pd.to_numeric,errors='coerce')\n\ndf['hp']=hp\ndf['engineVolume_L']=liters\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" df=df.drop(['model','ext_col','int_col','engine'],axis=1,errors='ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>[comments]</b>\nNow, we can see, we have 11 feature column  + 1 target column. \nNext I will check the Distribution and the relationship between feature and target","metadata":{}},{"cell_type":"code","source":"df.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check missing values\ncheck_miss_value(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for numerical variables\ndf.describe()  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for numerical variables\ndf.hist(figsize=(16,10),bins=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # for cat variables\ndf.select_dtypes(exclude=[np.number]).describe() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['fuel_type'].value_counts().plot.barh()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features=df.select_dtypes(include=[np.number]).columns.tolist()\ncat_features=df.select_dtypes(exclude=[np.number]).columns.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Exploratory Data distribution","metadata":{}},{"cell_type":"code","source":"df_train2=pd.concat([ df[:df_train.shape[0]],\n                          pd.DataFrame({'price':y_train})],\n                        axis=1)\nprint(df_train2.head())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test=df[df_train.shape[0]:df_train.shape[0]+df_test.shape[0]].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf=df_train2.copy()\ng=df.groupby('brand').agg({'price':['mean','count']}).sort_values(('price','mean'),ascending=False)\nprint(g.head())\nprint(g.shape)\n\nfig,ax=plt.subplots(figsize=(15,6))\nax2=ax.twinx()\n\ng.plot.bar(ax=ax,y=('price','mean'),label='Average Price',color='orange')\ng.plot.line(ax=ax2,y=('price','count'),color='blue',ls='--',lw=1,marker='.',label='Number of Instances')\n#ax2.axhline(2,ls='--',color='black')\nax.legend(loc='upper left')\nax2.legend(loc='upper right')\nax2.set_yscale('log')\nax.set_title('Average Price And Count Of Instances By Brand',fontweight='bold')\nax.set_ylabel('Average Price')\nax2.set_ylabel('Number of Instances')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def boxDist(df,target,object_names):\n    '''\n    For each categorical feature, check and plot distribution of target value  and \n    enumerate them with boxplot; \n    \n    Only work when object feature has limtited values\n    \n    args:\n        df: a pd dataset inlcuding features+targe columns\n        target: (str) y_name\n        object_names:a list of names \n    returen:\n    \n    '''\n    def boxplot(x,y, **kws):\n        '''\n        plot boxplot distribution for object features\n        arg: x ,y\n        '''\n        sns.boxplot(x=x,y=y)\n        plt.xticks(rotation=90)\n    \n    f=pd.melt(frame=df,id_vars=[target],value_vars=object_names)\n    print(f.head())\n    g=sns.FacetGrid(f,col='variable',col_wrap=2,sharex=False,sharey=False)\n    g=g.map(boxplot,'value',target)\n    plt.show()\n    \ndef countPlot(df,cat_names):\n    '''\n    For categorical features, ploting countplot for each features\n    args:\n        df: pd dataFrame\n        cat_names: (list) of categorical features` name\n    return:\n        bar graph\n    \n    '''\n    fig, axes = plt.subplots(len(cat_names),\n                             figsize=(12, 3*cat_names))\n    axes = axes.ravel()  # Flatten the 2D array of axes\n    \n    for i, column in enumerate(categorical_columns):\n        sns.countplot(x=df[column], \n                      data=df,\n                      palette='bright', \n                      ax=axes[i], \n                      saturation=0.95)\n        for container in axes[i].containers:\n            axes[i].bar_label(container, color='black', size=10)\n        axes[i].set_title(f'Count Plot of {column.capitalize()}')\n        axes[i].set_xlabel(column.capitalize())\n        axes[i].set_ylabel('Count')\n\n    # Adjust layout and show plots\n    plt.tight_layout()\n    plt.show()\n    \ndef perctDist(df,cat_names):\n    '''\n    For categorical features, geting the values distribution for object features\n    return  percentage distribution graph for each feature\n    \n    inputs:\n        df: pd dataset\n        cat_names: a list of column names\n    '''\n    num_col=len(cat_names)\n    for i in np.arange(num_col):\n        fig,ax=plt.subplots(nrows=1,ncols=2,\n                           gridspec_kw={'width_ratios': [2, 1]},\n                           figsize=(20,10))\n        print(cat_names[i])\n        txt=100*df[cat_names[i]].value_counts()/df[cat_names[i]].value_counts().sum()\n#         print(txt)\n        ax[0].plot(txt,marker='*')\n        ax[0].set_xlabel(cat_names[i] )\n        ax[0].set_ylabel('percentage dist.')\n        ax[0].set_xticks(range(len(txt.index)))\n        ax[0].set_xticklabels(labels=txt.index,rotation=90)\n        \n        ax[1].pie(txt)\n        \n\n    plt.show()\n    \n\ndef fliersOutBox(series):\n    '''\n    Find margnial values for each feature\n    \n    args:\n        series: pd DatfRAME\n    returns:\n            the indexes of the filers\n    '''\n    # quantile_values q1 q2 q3\n    q1,q2,q3=np.quantile(series,\n                         q=[0.25, 0.5, 0.75],\n                        axis=0)\n#     print(quantile_values)\n    iqr=q3-q1\n    whisker_low=q1-1.5*iqr\n    whisker_up=q3+1.5*iqr\n    print(f\"quantile vlaues for 0.25,0.5,0.75 is {q1,q2,q3}\")\n    print(f\"whisker_low is {whisker_low}\")\n    print(f\"whisker_up is {whisker_up}\")\n    fliers=series[((series <whisker_low )|(series >whisker_up ))]\n    return(fliers.index.tolist())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scatterPlot(df,num_features):\n    '''\n    For numerical features, plt scatter and  numer_features vs target values\n    args:\n        df: pd dataframe\n        num_features a list of num_feature names +targe_names\n    ''' \n    fig,ax=plt.subplots(len(num_features)-1,figsize=(6,5*(len(num_features)-1)))\n    for i in np.arange(len(num_features)-1):\n        ax[i].scatter(df[num_features[i]], df[num_features[-1]])\n        ax[i].set_ylabel(num_features[-1])\n        ax[i].set_xlabel(num_features[i])\ndef pairScatter(df,num_features):\n    '''\n    For numerical features, plt scatter for pais of features\n    and  numer_features vs target values\n    args:\n        df: pd dataframe\n        num_features: a list of num_feature names\n    ''' \n#     fig,ax=plt.subplots(l\n    sns.pairplot(df[num_features],height=2.5)\n\n    \n\ndef boxPlot(df,num_features):\n    '''\n    for numerical features,  boxplotfor numer_features vs target values\n    work well with limited number of values for each features\n    args:\n        df: pd dataframe\n        num_features a list of num_feature names +targe_names\n    ''' \n    fig,ax=plt.subplots(len(num_features)-1,\n                          figsize=(6,5*(len(num_features)-1)))\n    for i in np.arange(len(num_features)-1):\n        sns.boxplot(x=df[num_features[i]],y= df[num_features[-1]])#,ax=ax[i])\n#         ax[i].set_ylabel(num_features[-1])\n#         ax[i].set_xlabel(num_features[i])\n        \ndef histPlot(df,num_features):\n    '''\n    For numerical features, for numerical features,  \n    args:\n        df: pd dataframe\n        num_features a list of num_feature names +targe_names\n    ''' \n    fig,ax=plt.subplots(len(num_features),figsize=(6,5*(len(num_features)-1)))\n    for i in np.arange(len(num_features)):\n        sns.histplot(df[num_features[i]],kde='True',ax=ax[i])\n#         ax[i].hist(df[num_features[i]],color='g',bins=50)\n#         ax[i].set_ylabel(num_features[-1])\n        ax[i].set_xlabel(num_features[i])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check distribution for numberical features  \nnum_features=['model_year',\n 'milage',\n 'transmission',\n 'accident',\n 'hp',\n 'engineVolume_L', 'price']\n\nprint(df[num_features].describe())\n\nscatterPlot(df,num_features)\n\npairScatter(df,num_features)\nhistPlot(df,num_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>[comments]</b>\n- margnial values:\n\n     model_year <1980\n     milage >350000\n     hp>1000 \nhp eng corr+\n","metadata":{}},{"cell_type":"markdown","source":" <font size='+3' color=red> Drop  outliers (marginal values) </font>","metadata":{}},{"cell_type":"code","source":"y_price_fliers_inx=fliersOutBox(df['price'])\nprint(len(y_price_fliers_inx))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop outler the inx\ninx=[693,3046,\\\n    40126,39640,8674,46001,42738,15749,15822,\\\n    34757,19882,25873]\n# df=df[df.price<2e6]\ndf_drop=df.drop(inx,axis=0)\ndf_drop.reset_index(drop=True,inplace=True)\nprint(f\"The train (df_drop) size now is {df_drop.shape}\")\n# df_drop.tail()\nscatterPlot(df_drop,num_features)\n\npairScatter(df_drop,num_features)\nhistPlot(df_drop,num_features)\nboxDist(df_drop,'price',cat_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generally get ride of margnial values\n# remove rare brand with count <2 \nprint(df_drop.shape)\ndf_drop=df_drop.groupby('brand').filter(lambda x:x['model_year'].count()>2) #remove rare brand\nprint(df_drop.shape)\n\n# df.select_dtypes('O').describe()\n\n# remove fuel_type  with count <2 \nprint(df_drop.shape)\ndf_drop=df_drop.groupby('fuel_type').filter(lambda x:x['model_year'].count()>2) #remove rare brand\nprint(df_drop.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_drop.select_dtypes('O').describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"boxDist(df_drop,'price',cat_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# general kick out margnial values for numerical features\n# drop numerical values outside of mean+- 2std \n#Two sigmas above or below would include about 95 percent of the data,\nprint(df_drop.shape)\nfor col in num_features:\n    print(col)\n    num_mean=df[col].mean()\n    num_std=df[col].std()\n    low_bound=num_mean- 2*num_std\n    up_bound=num_mean+2*num_std\n    df_drop[ (df_drop[col]>low_bound) & (df_drop[col]<up_bound) ]\n\nprint(df_drop.shape)\ndf_drop.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_features=['model_year',\n#  'milage',\n#  'transmission',\n#  'accident',\n#  'hp',\n#  'engineVolume_L', 'price']\n# scatterPlot(df,num_features)\n\n# pairScatter(df,num_features)\n# histPlot(df,num_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color=purple size=6> impute/drop the missing value </font>","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_miss_value(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_miss_value(df_drop)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_drop[['engineVolume_L','hp']].dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_drop[['engineVolume_L','hp']].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imp_med=SimpleImputer(strategy='median')\nimp_med.fit(df_drop[['engineVolume_L','hp']])\nimp_med.get_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imp_med=SimpleImputer(strategy='median')\n# imp_med.fit(df_drop[['engineVolume_L','hp']])\n\ndf_drop[['engineVolume_L','hp']]=imp_med.transform(\n    df_drop[['engineVolume_L','hp']])\nX_test[['engineVolume_L','hp']]=imp_med.transform(\n    X_test[['engineVolume_L','hp']])\ncheck_miss_value(df_drop)\ncheck_miss_value(X_test)\n\n# imp_const=SimpleImputer(strategy='constant',fill_value='No')\n\n# df_drop[['imp_clean_title']]=imp_const.fit_transform(df_drop[['clean_title']])\n\n# imp_features=['imp_fuel_type','imp_accident','imp_clean_title']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimp_freq=SimpleImputer(strategy='most_frequent')\nX_test[['fuel_type']]=imp_freq.fit_transform(X_test[['fuel_type']])\ncheck_miss_value(df_drop)\ncheck_miss_value(X_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.5 reduce cardinality for categorical values","metadata":{}},{"cell_type":"code","source":"df_drop.select_dtypes(exclude=[np.number]).describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perctDist(df_drop,cat_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>[comments]</b>\n - model and engine will be not considerd in the following as the huge diversity of the values ","metadata":{}},{"cell_type":"code","source":"def groupCardinality (df,obj_names,tops):\n    '''\n    For high cardinality of cateogrical featuers, only kep the tops number\n    individual features and group the others\n    args:\n        df dataframe\n        obj_name: (str) the name of the feautres\n        tops: (int) the number of levels treated individually\n    return:\n        df: dataframe with a new column named as group_obj_names\n    '''\n    txt=100*df[obj_names].value_counts()/df[obj_names].value_counts().sum()\n    txt.sort_values(ascending=False,inplace=True)\n    print('The accumutive percentage of the top {} level of {} is {:.2f}%'.format(tops,obj_names, txt[:tops].sum()))\n    print('The top {} level are {}'.format( tops,txt[:tops].index.tolist()))\n    print()\n    \n    df['group_'+obj_names]=df[obj_names].map(lambda x: x if x in txt[:tops].index.tolist() else 'Others' )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# groupCardinality(df_drop,'model',40)\n# groupCardinality(df_drop,'engine',40)\n# groupCardinality(df_drop,'ext_col',6)\n# groupCardinality(df_drop,'brand',15)\n# groupCardinality(df_drop,'int_col',7)\n# groupCardinality(df_drop,'imp_fuel_type',1)\n# groupCardinality(df_drop,'transmission',9)\n\n# grouped_features= ['group_'+i for i in \n#                    ['model','engine',\n#                     'ext_col','brand','int_col','imp_fuel_type','transmission']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-14T21:04:56.633425Z","iopub.execute_input":"2024-06-14T21:04:56.633911Z","iopub.status.idle":"2024-06-14T21:04:56.639435Z","shell.execute_reply.started":"2024-06-14T21:04:56.633868Z","shell.execute_reply":"2024-06-14T21:04:56.638159Z"}}},{"cell_type":"code","source":"df_drop.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \nboxDist(df_drop, 'price',\n         ['brand','fuel_type'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.6 Correlation for numerical features","metadata":{}},{"cell_type":"code","source":"def spearman(df,features):\n    '''\n       Get correlation of numerical features with target Y values\n       feature_frame=features + y_value\n       args:\n           df: pd dataFrame [NUM]features columns + target Y column as the last\n           features: (list) of feature names\n           \n       return: a barh showing correlations between each fearue and y, \n               where x-axis is the correlations-value\n       '''\n    spr=pd.DataFrame()\n    # get feature name\n    spr['feature']=features\n    # get correlations between each feature and y targets\n    spr['spearman']=[df[f].corr(df.iloc[:,-1]) for f in features]\n    spr.sort_values('spearman',inplace=True)\n    \n    plt.figure(  figsize=(6,0.25*len(features)))\n    sns.barplot(data=spr,x='spearman',y='feature',orient='h')\n\ndef corrDist(df,yname,k=df.shape[1]):\n    '''\n    plt heatmap for correlations \n    args:\n        df: dataFrame including num_feature+Y_target value \n        yname: the targe column name\n        k: (int) the top numer of feaures which has highest correlation value with y will be plot \n        \n    return:\n    '''\n    fig,ax=plt.subplots()\n    corr=df.corr()\n    cols=corr.nlargest(k,yname)[yname].index\n    cm=np.corrcoef(df[cols].values.T)\n    \n    mask = np.zeros_like(cm, dtype = np.bool_)\n    mask[np.triu_indices_from(mask)] = True\n    sns.heatmap(cm,cbar=True,\n                annot=True,\n                mask=mask,\n                fmt='.2f', \n                annot_kws={'size':10},\n                yticklabels=cols.values,\n                xticklabels=cols.values,\n           ax=ax)\n    print(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features=df_drop.select_dtypes( include=[np.number]).columns.tolist()\nnum_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features=['model_year',\n 'milage',\n 'transmission',\n 'accident',\n 'hp',\n 'engineVolume_L', 'price']\nnum_features2=['model_year',\n 'milage',\n 'transmission',\n 'accident',\n 'hp',\n 'engineVolume_L']\n\nspearman(df_drop[num_features],num_features2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corrDist(df_drop[num_features]\n         ,'price')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>[comment]</b>\n    \nnew car with less milage has a great price","metadata":{"execution":{"iopub.status.busy":"2024-06-17T21:01:14.012896Z","iopub.execute_input":"2024-06-17T21:01:14.013320Z","iopub.status.idle":"2024-06-17T21:01:14.023064Z","shell.execute_reply.started":"2024-06-17T21:01:14.013287Z","shell.execute_reply":"2024-06-17T21:01:14.021256Z"}}},{"cell_type":"markdown","source":"# <font color=purple size=5> Encode categorical variables </font>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_drop.select_dtypes(exclude=[np.number]).columns.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_drop.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_drop.reset_index(drop=True,inplace=True)\nX_test.reset_index(drop=True,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_drop.index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oh_enc=OneHotEncoder()\ncat_names=['brand', 'fuel_type']\noh_fit=oh_enc.fit(df_drop[cat_names])\n\noh_features_in=oh_fit.feature_names_in_\noh_features=oh_fit.get_feature_names_out().tolist()\n\noh_return=oh_fit.transform(df_drop[cat_names]).toarray()\nprint(oh_return.shape)\nprint(f\"the orignial {oh_fit.n_features_in_} \\\nhas been to {len(oh_features)} features\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oh_features_df=pd.DataFrame(oh_return,columns=oh_features)\ndf_drop=pd.concat([df_drop,oh_features_df], \n          axis=1)\ndf_drop.drop(columns=['brand', 'fuel_type'],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_drop.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_miss_value(df_drop)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for test\noh_enc_test=OneHotEncoder()\ncat_names=['brand', 'fuel_type']\noh_fit_test=oh_enc.fit(X_test[cat_names])\noh_features_in_test=oh_fit_test.feature_names_in_\noh_features_test=oh_fit_test.get_feature_names_out().tolist()\n\noh_return_test=oh_fit_test.transform(X_test[cat_names]).toarray()\n# oh_return.shape\nprint(f\"the orignial {oh_fit_test.n_features_in_} \\\nhas been to {len(oh_features_test)} features\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oh_features_df_test=pd.DataFrame(oh_return_test,columns=oh_features_test)\nX_test=pd.concat([X_test,oh_features_df_test], \n          axis=1)\n\nX_test.drop(columns=['brand', 'fuel_type'],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_miss_value(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color=purple size=5> Split datasets </font>\n\nno spliting ","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:49:15.111743Z","iopub.execute_input":"2024-06-17T18:49:15.112049Z","iopub.status.idle":"2024-06-17T18:49:15.120942Z","shell.execute_reply.started":"2024-06-17T18:49:15.112025Z","shell.execute_reply":"2024-06-17T18:49:15.119827Z"}}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df_drop.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train=df_drop['price']\nX_train=df_drop.drop(['price'],axis=1)\nprint(f\"The X_training size is {X_train.shape} and y_train is {y_train.shape}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train,X_test,y_train,y_test=train_test_split(X, y,\n#                                                      test_size=0.2,\n#                                                      random_state=33,\n#                                                     shuffle=True)\n# # X_train,X_dev, y_train,y_dev=train_test_split(X_traindev,y_traindev,\n# #                                                      test_size=0.2,\n# #                                                      random_state=33,\n# #                                                     shuffle=True)\n\n# print(f\"The X_training size is {X_train.shape} and y_train is {y_train.shape}\")\n# # print(f\"The X_dev size is {X_dev.shape} and y_train is {y_dev.shape}\")\n# print(f\"The X_test size is {X_test.shape} and y_train is {y_test.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color=green size=5> Transformation/Scaling for numerical features [training dataset] <font>","metadata":{}},{"cell_type":"code","source":"# convert an existing Python function into a transformer \nfrom sklearn.preprocessing import FunctionTransformer\nfrom scipy.stats import skew","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef boxPlot(df,num_features):\n    '''\n    for numerical features,  boxplotfor numer_features vs target values\n    work well with limited number of values for each features\n    args:\n        df: pd dataframe\n        num_features a list of num_feature names +targe_names\n    ''' \n    fig,ax=plt.subplots(len(num_features)-1,\n                          figsize=(6,5*(len(num_features)-1)))\n    for i in np.arange(len(num_features)-1):\n        sns.boxplot(x=df[num_features[i]],y= df[num_features[-1]])#,ax=ax[i])\n#         ax[i].set_ylabel(num_features[-1])\n#         ax[i].set_xlabel(num_features[i])\n        \ndef histDist(X_set,num_features):\n    '''\n    for numerical features,ploting hisgradm\n    args:\n        X_set: pd dataframe\n        num_features a list of num_feature names\n    ''' \n    fig,ax=plt.subplots(len(num_features),figsize=(6,5*(len(num_features))))\n    for i in np.arange(len(num_features)):\n        print(num_features[i])\n        sns.histplot(df[num_features[i]],kde='True',ax=ax[i])\n#         ax[i].hist(df[num_features[i]],color='g',bins=50)\n#         ax[i].set_ylabel(num_features[-1])\n        ax[i].set_xlabel(num_features[i])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef histDistY(y,yname):\n    '''\n    for numerical features,ploting hisgradm and \n    args:\n        y: a pd.series\n        yname (str)  names\n    ''' \n    fig,ax=plt.subplots(1,2,figsize=(14,6))\n\n    sns.histplot(y ,\n                 kde='True',\n                 stat='probability'\n                 ,ax=ax[0])\n    \n    ax[0].set_xlabel(yname)\n    stats.probplot(y,plot=ax[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import QuantileTransformer,MinMaxScaler,StandardScaler\nfrom scipy import stats\nfrom scipy.stats import boxcox, yeojohnson","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The skewness :{y_train.skew()}\")\nhistDistY(y_train, 'price')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_train_log=y_train.map(np.log)\nlog_trans = FunctionTransformer(func=np.log, \n                                validate=True,\n                               inverse_func=np.exp)\n\n# log_trans.fit(pd.DataFrame(y_train))\ny_train_log=log_trans.transform(pd.DataFrame(y_train))\ny_train_log=np.squeeze(y_train_log)\n \nprint(f\"The skewness after log transformation :{skew(y_train_log)}\")\nhistDistY(pd.Series(y_train_log), 'price')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(f\"The skewness :{X_train['model_year'].skew()}\")\nprint(f\"The skewness :{X_train['milage'].skew()}\")\nprint(f\"The skewness :{X_train['hp'].skew()}\")\nprint(f\"The skewness :{X_train['engineVolume_L'].skew()}\")\n\nhistDist(X_train,['model_year','milage','hp','engineVolume_L'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# milage\nsqrt_trans = FunctionTransformer(np.sqrt, validate=True)\nX_train['sqrt_milage']=sqrt_trans.transform(pd.DataFrame(X_train['milage']))\nX_test['sqrt_milage']=sqrt_trans.transform(pd.DataFrame(X_test['milage']))\nprint(f\"The skewness :{X_train['milage'].skew()}\")\nprint(f\"The skewness :{X_train['sqrt_milage'].skew()}\")\n\nfig, axes=plt.subplots(2,2,figsize=(20,20))\nsns.histplot(X_train['milage'],kde=True,stat='probability',ax=axes[0,0])\nstats.probplot(X_train['milage'],plot=axes[0,1])\nsns.histplot(X_train['sqrt_milage'],kde=True,stat='probability',ax=axes[1,0])\nstats.probplot(X_train['sqrt_milage'],plot=axes[1,1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hp\n# sqrt_trans = FunctionTransformer(np.sqrt, validate=True)\nX_train['sqrt_hp']=sqrt_trans.transform(pd.DataFrame(X_train['hp']))\nX_test['sqrt_hp']=sqrt_trans.transform(pd.DataFrame(X_test['hp']))\nprint(f\"The skewness :{X_train['hp'].skew()}\")\nprint(f\"The skewness :{X_train['sqrt_hp'].skew()}\")\n\nfig, axes=plt.subplots(2,2,figsize=(20,20))\nsns.histplot(X_train['hp'],kde=True,stat='probability',ax=axes[0,0])\nstats.probplot(X_train['hp'],plot=axes[0,1])\nsns.histplot(X_train['sqrt_hp'],kde=True,stat='probability',ax=axes[1,0])\nstats.probplot(X_train['sqrt_hp'],plot=axes[1,1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# engineVolume_L\n# sqrt_trans = FunctionTransformer(np.sqrt, validate=True)\nX_train['sqrt_engineVolume_L']=sqrt_trans.transform(pd.DataFrame(X_train['engineVolume_L']))\nX_test['sqrt_engineVolume_L']=sqrt_trans.transform(pd.DataFrame(X_test['engineVolume_L']))\n\nprint(f\"The skewness :{X_train['engineVolume_L'].skew()}\")\nprint(f\"The skewness :{X_train['sqrt_engineVolume_L'].skew()}\")\n\nfig, axes=plt.subplots(2,2,figsize=(20,20))\nsns.histplot(X_train['engineVolume_L'],kde=True,stat='probability',ax=axes[0,0])\nstats.probplot(X_train['engineVolume_L'],plot=axes[0,1])\nsns.histplot(X_train['sqrt_engineVolume_L'],kde=True,stat='probability',ax=axes[1,0])\nstats.probplot(X_train['sqrt_engineVolume_L'],plot=axes[1,1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[['model_year']].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_year\nmm_scaler=MinMaxScaler()\nmm_features=['mm_model_year']\nminmax_scaler=mm_scaler.fit(X_train[['model_year']])\nX_train[mm_features]=minmax_scaler.transform(X_train[['model_year']])\nX_test[mm_features]=minmax_scaler.transform(X_test[['model_year']])\n\nprint(X_train[mm_features].describe())\nprint(f\"The skewness :{X_train[['model_year']].skew()}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_year\nX_train['squared_mm_model_year']=X_train['mm_model_year']**2\nX_test['squared_mm_model_year']=X_test['mm_model_year']**2\n\n\ncube_trans = FunctionTransformer(lambda x:x**3, validate=True)\nX_train[['squared_mm_model_year']]=cube_trans.transform( X_train[['mm_model_year']])\n\n\nprint(f\"The skewness :{X_train['mm_model_year'].skew()}\")\nprint(f\"The skewness :{X_train['squared_mm_model_year'].skew()}\")\nfig, axes=plt.subplots(2,2,figsize=(20,20))\nsns.histplot(X_train['mm_model_year'],kde=True,stat='probability',ax=axes[0,0])\nstats.probplot(X_train['mm_model_year'],plot=axes[0,1])\n\nsns.histplot(X_train['squared_mm_model_year'],kde=True,stat='probability',ax=axes[1,0])\nstats.probplot(X_train['squared_mm_model_year'],plot=axes[1,1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.drop(columns=['model_year','mm_model_year',\\\n                      'milage','engineVolume_L','hp'],inplace=True)\n\nX_test.drop(columns=['model_year','mm_model_year',\\\n                      'milage','engineVolume_L','hp'],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"std_scaler= StandardScaler()\ncolumn_names= [ col for col in X_train.columns \n               if col not in oh_features+['transmission','accident']]\n\nstd_scaler.fit(X_train[column_names])\nstd_features=std_scaler.transform(X_train[column_names])\nstd_features_test=std_scaler.transform(X_test[column_names])\n\nX_train[column_names]=pd.DataFrame(std_features,columns=column_names)\nX_test[column_names]=pd.DataFrame(std_features_test,columns=column_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2 Feature engineering\n- remvoe the unimportant features \n- using xgb forgest to measure the importance of the faeture ","metadata":{}},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow_decision_forests as tfdf\nimport xgboost as xgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" def obj_to_cat(df,cat_cols):\n    '''\n    convert dtype to categorical type\n    \n    args:\n        df: pd dataframe\n        cat_cols: a (list) of ‘category’  columns \n        \n    return: ‘category’ type of columns\n    '''\n    print(cat_cols)\n    for col in cat_cols:\n        # 1st convert it to the categorical data type\n        df[col]=df[col].astype('category')\n        # 2nd if exiting null values\n        if df[col].isnull().any():\n            # new new categiry as NA\n            df[col]=df[col].cat.add_categories(['NA'])\n            df[col]=df[col].fillna('NA')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xgb_reg=xgb.XGBRegressor(enable_categorical=True)\n# xgb_features=[col for col in X_train.columns \n#          if col not in oh_features+grouped_features+\\\n#               ['model_year','mm_model_year','milage_format']]\n\n# # cat_names=X_train[xgb_features].select_dtypes(exclude=[np.number]).columns.tolist()\n# # ojb_to_cat(X_train,cat_names)\n\n# xgb_reg.fit(X_train[xgb_features],y_train_log)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(oh_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_reg=xgb.XGBRegressor(enable_categorical=True) # with default h-params\n# cat_names=X_train[xgb_features].select_dtypes(exclude=[np.number]).columns.tolist()\n# ojb_to_cat(X_train,cat_names)\n\nxgb_reg.fit(X_train,y_train_log)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impt_features=pd.DataFrame(xgb_reg.feature_importances_,\n                           columns=['importance'],\n                           index=X_train.columns)\nimpt_features.sort_values(by='importance',ascending=False,inplace=True)\nprint(impt_features.head(40))\nimpt_features.plot.barh()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using RFECV to determine the optimal number of features to keep\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.metrics import make_scorer, mean_squared_error\n\ndef rmse(y_ture,y_pred):\n    return(mean_squared_error(y_ture,y_pred,squared=True)) # \nrmse_scorer=make_scorer(rmse,greater_is_better=False) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# greater_is_better=True means no sing-flip\n\nmin_features_to_select=5\n\n# rfecv=RFECV(xgb_reg,#estimator\n#             step=1,# num of weakest feature to remove at each iteration\n#             cv=5,# will do selection features 5 times\n#             verbose=False,\n#             scoring=rmse_scorer,\n#             min_features_to_select = min_features_to_select)\n\n# rfecv.fit(X_train ,y_train_log)\n# print(\"Optimal number of features : %d\" %rfecv.n_features_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfecv.cv_results_.keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(rfecv.cv_results_['mean_test_score'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfecv.cv_results_.keys()\nn_subsets_of_features = len(rfecv.cv_results_[\"mean_test_score\"])\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Mean test score\")\nplt.errorbar(\n    range(min_features_to_select, n_subsets_of_features + min_features_to_select),\n    rfecv.cv_results_[\"mean_test_score\"],\n    yerr=rfecv.cv_results_[\"std_test_score\"],\n)\nplt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n# plt.vlines(rfecv.n_features_,-0.6,-0.4,color='r')\nplt.show()\nfeatures_kept = X_train.columns.values[rfecv.support_] \n\n# X_train_imp= X_train[features_kept]\n# X_test_imp=X_test[features_kept]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names=list(set(X_test.columns).intersection( set(X_train.columns)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" len(impt_features[(impt_features.importance>0)].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_impt=X_train[names].copy() #[impt_features[(impt_features.importance>0)].index]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_log.mean()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_log.max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_log.min()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_log.std()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_impt.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3 Model","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # doest use in this competation \n# '''\n# geneerate pipeline that \n# treats different features with different transformers, \n# while leaving some features untransformed\n\n# # in training dataset  \n# # y_train: y_train_log()  transform\n# # milage_format: sqrt_trans() transform\n# # model_year minmax_scaler() --> cube_trans()\n\n# '''\n\n# mm_scaler= MinMaxScaler()\n# passthrough= 'passthrough'\n# raw_features=[ col for col in X_train.columns \n#               if col not in ['milage_format','model_year']]\n\n\n# #  define the transformers for different features\n\n# num_trasnformer1=Pipeline(steps=[\n#     ('mm scaler',mm_scaler),\n#     ('cube trans',cube_trans)])\n# num_tranformer2=Pipeline(steps=[\n#     ('sqrt_trans',sqrt_trans)\n# ])\n\n# cat_transformer=Pipeline(steps=[\n#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n# ])\n\n# # creat a columnTransformer\n# preprocessor=ColumnTransformer(\n# transformers=[\n#     ('milage',num_tranformer2,['milage_format']),\n#     ('model_year1',num_trasnformer1, ['model_year']),\n#     ('others',passthrough, raw_features)\n# ])\n\n# # then you can \n# # preprocessor.fit_transform(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1 preprocess for test dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:00:56.425264Z","iopub.execute_input":"2024-06-19T17:00:56.425663Z","iopub.status.idle":"2024-06-19T17:00:56.431571Z","shell.execute_reply.started":"2024-06-19T17:00:56.425631Z","shell.execute_reply":"2024-06-19T17:00:56.429983Z"}}},{"cell_type":"markdown","source":"## 3.1 Model selection using X_train and y_train cv","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, RidgeCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1.1 linear regression","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:09:30.299924Z","iopub.execute_input":"2024-06-19T05:09:30.300378Z","iopub.status.idle":"2024-06-19T05:09:30.305304Z","shell.execute_reply.started":"2024-06-19T05:09:30.300347Z","shell.execute_reply":"2024-06-19T05:09:30.304064Z"}}},{"cell_type":"code","source":"linear=LinearRegression()\nlinear.fit(X_train_impt,y_train_log)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_linear=linear.predict(X_train_impt)\nprint(f\"The dev RMSE is { rmse( y_train_log,y_pred_linear):.4f}\")\nprint(f\"The socre of R^2 for linear is %.4f\" \\\n      %(linear.score(X_train_impt,y_train_log)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_y=pd.DataFrame({'y_true_log':y_train_log,\n               'y_pred_log':y_pred_linear,\n                'y_true':np.exp(y_train_log),\n                'y_pred':np.exp(y_pred_linear)})\nplt.scatter(_y['y_true_log'],\n           _y['y_pred_log'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(_y['y_true'],\n           _y['y_pred'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1.2 RidgeCV regression","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:09:44.548573Z","iopub.execute_input":"2024-06-19T05:09:44.548935Z","iopub.status.idle":"2024-06-19T05:09:44.553637Z","shell.execute_reply.started":"2024-06-19T05:09:44.548908Z","shell.execute_reply":"2024-06-19T05:09:44.552446Z"}}},{"cell_type":"code","source":"\nreg_ridgeCV=RidgeCV(alphas=np.logspace(-6, 6, 13),\n#                     cv=5,\n                    scoring=rmse_scorer,\n                   store_cv_values=True\n                   )\nreg_ridgeCV.fit(X_train_impt,y_train_log)\n\ny_pred_ridge=reg_ridgeCV.predict(X_train_impt)\nprint(f\"Best alpha is {reg_ridgeCV.alpha_:.0e}\" )\nprint(f\"The dev RMSE is { rmse( y_train_log, y_pred_ridge):.4f}\")\nprint(f\"The socre of R^2 for reg_ridgeCV is %.4f\" \\\n      %(reg_ridgeCV.score(X_train_impt,y_train_log)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_y=pd.DataFrame({'y_true_log':y_train_log,\n               'y_pred_log':y_pred_ridge,\n                'y_true':np.exp(y_train_log),\n                'y_pred':np.exp(y_pred_ridge)})\nplt.scatter(_y['y_true_log'],\n           _y['y_pred_log'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(_y['y_true'],\n           _y['y_pred'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1.3 XGBregressor","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:10:23.584310Z","iopub.execute_input":"2024-06-19T05:10:23.585296Z","iopub.status.idle":"2024-06-19T05:10:23.589421Z","shell.execute_reply.started":"2024-06-19T05:10:23.585260Z","shell.execute_reply":"2024-06-19T05:10:23.588241Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import RepeatedKFold, cross_val_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model\nreg_xgb=xgb.XGBRegressor(eval_metric=rmse_scorer)\n# Evaluate the model with repeated k-fold cross-validation\ncv=RepeatedKFold(n_splits=10,\n                 n_repeats=3,\n                 random_state=1)\n#evaluate model\ncv_scores=cross_val_score(reg_xgb,\n                          X=X_train_impt,\n                          y=y_train_log,\n                         scoring=rmse_scorer,\n                         cv=cv)\nprint(f\" Mean RMSE: %.3f+-(%.3f)\" %( cv_scores.mean(),cv_scores.std()))\n\n# xgb_params={}\n# DMatrix=xgb.DMatrix(data=X_dev_impt,\n#          label=y_dev_log)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" cv_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_xgb.fit(X_train_impt,y_train_log)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_train_log)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_xgb=reg_xgb.predict(X_train_impt)\n \n_y=pd.DataFrame({'y_true_log':y_train_log,\n               'y_pred_log':y_pred_xgb,\n                'y_true':np.exp(y_train_log),\n                'y_pred':np.exp(y_pred_xgb)})\nplt.scatter(_y['y_true_log'],\n           _y['y_pred_log'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(_y['y_true'],\n           _y['y_pred'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_xgb.get_booster()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(reg_xgb.get_params())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2  Xgboost_turning","metadata":{"execution":{"iopub.status.busy":"2024-06-23T04:41:26.845605Z","iopub.execute_input":"2024-06-23T04:41:26.846552Z","iopub.status.idle":"2024-06-23T04:41:26.850664Z","shell.execute_reply.started":"2024-06-23T04:41:26.846515Z","shell.execute_reply":"2024-06-23T04:41:26.849616Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import learning_curve","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training datasize\n\n\ndef plot_learning_curve(model,X,y):\n    '''\n    ploting performance as train_sizes\n    args:\n        X: X_train\n        y: y_train\n    return:\n    '''\n    #train_sizes (size of n_tickes)\n    # train_scores and test_scores (n_ticks, n_cv_folds)\n    train_sizes,train_scores,test_scores=learning_curve(estimator=model,\n                  X=X,\n                  y=y,\n                  train_sizes=[0.1, 0.33, 0.55, 0.78, 1.], #n_ticks=5\n                  cv=10,\n                  scoring=rmse_scorer)\n    \n    # calculate score for each tick\n    train_scores_mean=np.mean(train_scores,axis=1)\n    train_scores_std=np.std(train_scores,axis=1)\n    test_scores_mean=np.mean(test_scores,axis=1)\n    test_scores_std=np.std(test_scores,axis=1)\n    \n    plt.figure(figsize=(10, 6))\n    plt.plot(train_sizes,\n             train_scores_mean, \n             label='Training Accuracy', \n             color='blue')\n    plt.fill_between(train_sizes, \n                     train_scores_mean -2*train_scores_std,\n                     train_scores_mean + 2*train_scores_std,\n                     alpha=0.2, color='blue')\n   \n    plt.plot(train_sizes, test_scores_mean, \n             label='Validation Accuracy', color='green')\n    plt.fill_between(train_sizes, \n                     test_scores_mean - 2*test_scores_std, \n                     test_scores_mean + 2*test_scores_std, \n                     alpha=0.2, color='green')\n    \n    plt.xlabel('Training Set Size')\n    plt.ylabel('Mean RMSE')\n    plt.title('Learning Curve')\n    plt.legend(loc='best')\n    plt.grid(True)\n    plt.show()\n    print(train_sizes)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_impt.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training datasize\n\nreg_xgb=xgb.XGBRegressor(eval_metric=rmse_scorer)\n%time plot_learning_curve(reg_xgb,X_train_impt,y_train_log)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> [comments]</b>\n\nRMSE_train<RMSE_dev --> variance (overfitting)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T19:04:23.028272Z","iopub.execute_input":"2024-06-22T19:04:23.028756Z","iopub.status.idle":"2024-06-22T19:04:23.037457Z","shell.execute_reply.started":"2024-06-22T19:04:23.028718Z","shell.execute_reply":"2024-06-22T19:04:23.035404Z"}}},{"cell_type":"code","source":"# search on hyper parameters\nfrom sklearn.model_selection import RandomizedSearchCV,GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# default n_estimators=100,max_depth=6, learning_Rate=0.3\nreg_xgb=xgb.XGBRegressor(eval_metric=rmse_scorer)\nrmse_scorer=make_scorer(rmse,greater_is_better=False) \n\nparam_grid={'n_estimators':[100,500,1000,2000],\n            'max_depth':[3,5,8,10],\n            'learning_rate':[0.01,0.05,0.1,0.15]}\nrand_search_cv=RandomizedSearchCV(estimator=reg_xgb,\n#                             param_grid=param_grid,\n                          param_distributions=param_grid,\n                                  cv=5,\n                          n_iter=10,\n                          scoring=rmse_scorer, #'neg_mean_squared_error',\n                           verbose=4,\n                          random_state=1234,\n                          )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nrand_search_cv.fit(X_train_impt,y_train_log)\n\nprint()\nbest_xgb=rand_search_cv.best_estimator_\nprint(f\"Mean RMSE for the best model is {rand_search_cv.best_score_:.2f}\")\nprint(f\"best params_  for the best model is {rand_search_cv.best_params_}\")\n   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbest_xgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_learning_curve(best_xgb,X_train_impt,y_train_log)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_best_xgb=best_xgb.predict(X_train_impt)\n\n_y=pd.DataFrame({'y_true_log':y_train_log,\n               'y_pred_log':y_pred_best_xgb,\n                'y_true':np.exp(y_train_log),\n                'y_pred':np.exp(y_pred_best_xgb)})\nplt.scatter(_y['y_true_log'],\n           _y['y_pred_log'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(_y['y_true'],\n           _y['y_pred'])\n# plt.xlim(1,2e6)\n# plt.ylim(1,60000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_log_pred=pd.DataFrame({'price':best_xgb.predict(X_train_impt)})\n                                 \nprint(y_train_log_pred[0:5])\ny_train_pred=np.squeeze(log_trans.inverse_transform(y_train_log_pred ))\nprint(y_train_pred[0:5])\nprint(y_train[0:5])\nrmse_train=rmse(y_train,y_train_pred)\n\n# rmse_train.mean()\n# rmse_train.std()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# names=list(set(X_test.columns).intersection( set(X_train.columns)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test=X_test[names]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[0:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_log[0:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Error Analysis","metadata":{"execution":{"iopub.status.busy":"2024-06-22T20:02:59.388014Z","iopub.execute_input":"2024-06-22T20:02:59.388468Z","iopub.status.idle":"2024-06-22T20:02:59.394281Z","shell.execute_reply.started":"2024-06-22T20:02:59.388431Z","shell.execute_reply":"2024-06-22T20:02:59.392884Z"}}},{"cell_type":"code","source":"fig, (ax1,ax2)=plt.subplots(1,2,figsize=(15,5))\nax1.scatter(np.exp(y_train_log),np.exp(y_pred))\nax1.set_xlabel('actual')\nax1.set_ylabel('prediction')\nax1.set_title('Train')\n# ax2.scatter(y_test,test_prediction,c=(y_test-test_prediction).abs(),cmap='autumn')\n# ax2.set_xlabel('actual')\n# ax2.set_ylabel('prediction')\n# ax2.set_title('Test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}